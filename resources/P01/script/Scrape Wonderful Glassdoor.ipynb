{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not run all cells at once\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"./Scraped Data Wonderful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information we want to scrape\n",
    "MainData = pd.DataFrame(columns = ['Summary','Date', 'OverallRating', 'WorkLifeBalance', 'CultureValues', 'CareerOpportunities', 'CompBenefits', 'SeniorManagement', 'Pros', 'Cons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function that is reusable. We need to scrape many pages of many companies\n",
    "def SCRAPER(url):\n",
    "    global MainData\n",
    "    #Define some lists\n",
    "    WorkLifeBalance = []\n",
    "    CultureValues=[]\n",
    "    CareerOpportunities=[]\n",
    "    CompBenefits=[]\n",
    "    SeniorManagement=[]    \n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    req = Request(url,headers=hdr)\n",
    "    page = urlopen(req)\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    #Get the summary\n",
    "    Summary = soup.find_all('span', attrs = {'class':'summary'})\n",
    "    SummaryClean = []\n",
    "    for x in Summary:\n",
    "        SummaryClean.append(x.text)\n",
    "    \n",
    "    #Get Postdate\n",
    "    PostDate = soup.find_all('time', attrs = {'class':'date subtle small'})\n",
    "    PostDateClean = []\n",
    "    for x in PostDate:\n",
    "        PostDateClean.append(x['datetime'])\n",
    "        \n",
    "    #Get overall rating\n",
    "    ValueTitle = soup.find_all('span', attrs = {'class':'value-title'})\n",
    "    ValueTitleClean = []\n",
    "    for x in ValueTitle:\n",
    "        ValueTitleClean.append(x['title'])\n",
    "    \n",
    "    #Get subratings. Since a user can choose not to rate in some categories, things are more complicated\n",
    "    SubRatings= soup.find_all('div', attrs = {'class':'subRatings module'})\n",
    "    for subrating in SubRatings:\n",
    "        RatingCat=subrating.find_all('div', attrs = {'class':'minor'})\n",
    "        RatingCatClean = []\n",
    "        for x in RatingCat:\n",
    "            RatingCatClean.append(x.text)\n",
    "        RatingVal=subrating.find_all('span', attrs = {'class':'gdBars gdRatings med '})\n",
    "        RatingValClean = []\n",
    "        for x in RatingVal:\n",
    "            RatingValClean.append(x['title'])\n",
    "        try:\n",
    "            index = RatingCatClean.index('Work/Life Balance')\n",
    "        except ValueError:\n",
    "            index=100\n",
    "        RatingValue = WorkLifeBalance.append(None) if index==100 else WorkLifeBalance.append(RatingValClean[index])\n",
    "        try:\n",
    "            index = RatingCatClean.index('Culture & Values')\n",
    "        except ValueError:\n",
    "            index=100\n",
    "        RatingValue = CultureValues.append(None) if index==100 else CultureValues.append(RatingValClean[index])\n",
    "        try:\n",
    "            index = RatingCatClean.index('Career Opportunities')\n",
    "        except ValueError:\n",
    "            index=100\n",
    "        RatingValue = CareerOpportunities.append(None) if index==100 else CareerOpportunities.append(RatingValClean[index])\n",
    "        try:\n",
    "            index = RatingCatClean.index('Comp & Benefits')\n",
    "        except ValueError:\n",
    "            index=100\n",
    "        RatingValue = CompBenefits.append(None) if index==100 else CompBenefits.append(RatingValClean[index])\n",
    "        try:\n",
    "            index = RatingCatClean.index('Senior Management')\n",
    "        except ValueError:\n",
    "            index=100\n",
    "        RatingValue = SeniorManagement.append(None) if index==100 else SeniorManagement.append(RatingValClean[index]) \n",
    "    \n",
    "    #Get Pros\n",
    "    Pros = soup.find_all('p', attrs = {'class':' pros mainText truncateThis wrapToggleStr'})\n",
    "    ProsClean = []\n",
    "    for x in Pros:\n",
    "        ProsClean.append(x.text)    \n",
    "    \n",
    "    #Get Cons\n",
    "    Cons = soup.find_all('p', attrs = {'class':' cons mainText truncateThis wrapToggleStr'})\n",
    "    ConsClean = []\n",
    "    for x in Cons:\n",
    "        ConsClean.append(x.text)    \n",
    "        #Get the overall rating\n",
    "    DATA = pd.DataFrame(list(zip(SummaryClean, PostDateClean, ValueTitleClean, WorkLifeBalance, CultureValues, CareerOpportunities, CompBenefits, SeniorManagement, ProsClean, ConsClean)), columns = ['Summary','Date', 'OverallRating', 'WorkLifeBalance', 'CultureValues', 'CareerOpportunities', 'CompBenefits', 'SeniorManagement', 'Pros', 'Cons'])\n",
    "    MainData=MainData.append(DATA,)\n",
    "    #Wait a little\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Wonderful Glassdoor Data\n",
    "for x in range(1,10):\n",
    "    url=\"https://www.glassdoor.com/Reviews/The-Wonderful-Company-Reviews-E1005987_P\"+str(x)+\".htm?sort.sortType=RD&sort.ascending=false\"\n",
    "    SCRAPER(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "MainData = pd.DataFrame(columns = ['Summary','Date', 'OverallRating', 'WorkLifeBalance', 'CultureValues', 'CareerOpportunities', 'CompBenefits', 'SeniorManagement', 'Pros', 'Cons'])\n",
    "#Scrappe Dole Glassdoor Data\n",
    "for x in range(1,6):\n",
    "    url=\"https://www.glassdoor.com/Reviews/Dole-Food-Reviews-E136_P\"+str(x)+\".htm?sort.sortType=RD&sort.ascending=false\"\n",
    "    SCRAPER(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "MainData = pd.DataFrame(columns = ['Summary','Date', 'OverallRating', 'WorkLifeBalance', 'CultureValues', 'CareerOpportunities', 'CompBenefits', 'SeniorManagement', 'Pros', 'Cons'])\n",
    "#Scrappe Dole Glassdoor Data\n",
    "for x in range(1,16):\n",
    "    url=\"https://www.glassdoor.com/Reviews/General-Mills-Reviews-E278_P\"+str(x)+\".htm?sort.sortType=RD&sort.ascending=false\"\n",
    "    SCRAPER(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "MainData = pd.DataFrame(columns = ['Summary','Date', 'OverallRating', 'WorkLifeBalance', 'CultureValues', 'CareerOpportunities', 'CompBenefits', 'SeniorManagement', 'Pros', 'Cons'])\n",
    "#Scrappe Dole Glassdoor Data\n",
    "for x in range(1,8):\n",
    "    url=\"https://www.glassdoor.com/Reviews/Chiquita-Brands-Reviews-E694_P\"+str(x)+\".htm?sort.sortType=RD&sort.ascending=false\"\n",
    "    SCRAPER(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "MainData = pd.DataFrame(columns = ['Summary','Date', 'OverallRating', 'WorkLifeBalance', 'CultureValues', 'CareerOpportunities', 'CompBenefits', 'SeniorManagement', 'Pros', 'Cons'])\n",
    "#Scrappe Dole Glassdoor Data\n",
    "for x in range(1,30):\n",
    "    url=\"https://www.glassdoor.com/Reviews/Mondelez-International-Reviews-E628257_P\"+str(x)+\".htm?sort.sortType=RD&sort.ascending=false\"\n",
    "    SCRAPER(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write files\n",
    "MainData=MainData.reset_index(drop=True)\n",
    "MainData.to_csv('Modelez_Glassdoor_Data.csv', mode = 'w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
